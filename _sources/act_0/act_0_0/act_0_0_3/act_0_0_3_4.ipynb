{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seasons 2.0\n",
    "## Combining individual-level and group-level data\n",
    "### Demonstration of the `mepoisson` command in Stata; ultimately translate to R\n",
    "\n",
    "#### 1\n",
    "\n",
    "```stata\n",
    "set timeout1 1000\n",
    "//global data \"https://github.com/muzaale/got/raw/main/act_5/act_5_9/\"\n",
    "//use $data, clear\n",
    "cd \"~/dropbox/1f.ἡἔρις,κ/1.ontology\"\n",
    "use donor_live_keep_v, clear\n",
    "if 0 { //no need to collapse & merge with this syntax!\n",
    "    recode don_relation (1/4=1)(5/999=0), gen(related)\n",
    "    recode don_race (8=1)(16=2)(2000=3)(64=4)(24/1500 .=5), gen(racecat)\n",
    "    \n",
    "    gen year = year(don_recov_dt)\n",
    "    gen month = month(don_recov_dt)\n",
    "    \n",
    "    tab year \n",
    "    \n",
    "    egen n_year = count(don_recov_dt), by(year)\n",
    "    egen n_month = count(don_recov_dt), by(year month)\n",
    "    \n",
    "    poisson n_year year\n",
    "    poisson n_month year month\n",
    "    \n",
    "    tab month, matcell(cellvalues)\n",
    "    \n",
    "    local freq_jan = cellvalues[1,1]\n",
    "    local freq_jun = cellvalues[6,1]\n",
    "    local ratio = `freq_jun' / `freq_jan'\n",
    "    \n",
    "    di `ratio'\n",
    "    \n",
    "    gen count = 1\n",
    "    \n",
    "    recode month (1/5 9/12=0)(6/8=1), gen(summer)\n",
    "}\n",
    "\n",
    "* We have individual-level data to this point\n",
    "preserve\n",
    "    collapse (count) count=pers_id, by(summer)\n",
    "    di (count[2]/3)/(count[1]/9) //back-of-envelope irr\n",
    "restore \n",
    "preserve \n",
    "    * Collapse the data to get the total count for each group\n",
    "    collapse (count) donations=pers_id, by(year month summer)\n",
    "    //twoway (scatter count year)\n",
    "    * Save the aggregated data\n",
    "    tempfile aggregated_data\n",
    "    save `aggregated_data'\n",
    "restore \n",
    "\n",
    "* Merge the aggregated count back to the individual-level data\n",
    "merge m:1 year month summer using `aggregated_data'\n",
    "\n",
    "* Now, you've both group-level and individual-level variables as predictors\n",
    "* Run the single-level Poisson model first to get starting estimates\n",
    "poisson donations summer related, irr iter(5)\n",
    "\n",
    "* Capture the estimates\n",
    "matrix start_vals = e(b)\n",
    "\n",
    "if 0 {\n",
    "\t* Assuming `start_vals' is a matrix containing your starting values\n",
    "    matrix start_vals = (0.1 \\ 0.2 \\ 0.3) \n",
    "\n",
    "    * Use the `from()' option to start the optimization from these values\n",
    "    mepoisson donations || summer:, irr from(start_vals) iter(3)\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "#### 2\n",
    "\n",
    "```stata\n",
    ". do \"/var/folders/sx/fd6zgj191mx45hspzbgwzlnr0000gn/T//SD16143.000000\"\n",
    "\n",
    ". set timeout1 1000\n",
    "\n",
    ". //global data \"https://github.com/muzaale/got/raw/main/act_5/act_5_9/\"\n",
    ". //use $data, clear\n",
    ". cd \"~/dropbox/1f.ἡἔρις,κ/1.ontology\"\n",
    "/Users/d/Dropbox (Personal)/1f.ἡἔρις,κ/1.ontology\n",
    "\n",
    ". use donor_live_keep_v, clear\n",
    "\n",
    ". if 0 { //no need to collapse & merge\n",
    ".     recode don_relation (1/4=1)(5/999=0), gen(related)\n",
    ".     recode don_race (8=1)(16=2)(2000=3)(64=4)(24/1500 .=5), gen(racecat)\n",
    ".     \n",
    ".     gen year = year(don_recov_dt)\n",
    ".     gen month = month(don_recov_dt)\n",
    ".     \n",
    ".     tab year \n",
    ".     \n",
    ".     egen n_year = count(don_recov_dt), by(year)\n",
    ".     egen n_month = count(don_recov_dt), by(year month)\n",
    ".     \n",
    ".     poisson n_year year\n",
    ".     poisson n_month year month\n",
    ".     \n",
    ".     tab month, matcell(cellvalues)\n",
    ".     \n",
    ".     local freq_jan = cellvalues[1,1]\n",
    ".     local freq_jun = cellvalues[6,1]\n",
    ".     local ratio = `freq_jun' / `freq_jan'\n",
    ".     \n",
    ".     di `ratio'\n",
    ".     \n",
    ".     gen count = 1\n",
    ".     \n",
    ".     recode month (1/5 9/12=0)(6/8=1), gen(summer)\n",
    ". }\n",
    "\n",
    ". \n",
    ". * We have individual-level data to this point\n",
    ". preserve\n",
    "\n",
    ".     collapse (count) count=pers_id, by(summer)\n",
    "\n",
    ".     di (count[2]/3)/(count[1]/9) //back-of-envelope irr\n",
    "1.141058\n",
    "\n",
    ". restore \n",
    "\n",
    ". preserve \n",
    "\n",
    ".     * Collapse the data to get the total count for each group\n",
    ".     collapse (count) donations=pers_id, by(year month summer)\n",
    "\n",
    ".     //twoway (scatter count year)\n",
    ".     * Save the aggregated data\n",
    ".     tempfile aggregated_data\n",
    "\n",
    ".     save `aggregated_data'\n",
    "file /var/folders/sx/fd6zgj191mx45hspzbgwzlnr0000gn/T//S_16143.000003 saved as .dta\tformat\n",
    "\n",
    ". restore \n",
    "\n",
    ". \n",
    ". * Merge the aggregated count back to the individual-level data\n",
    ". merge m:1 year month summer using `aggregated_data'\n",
    "\n",
    "Result                      Number of obs\n",
    "\n",
    "Not matched                             0\n",
    "Matched                           186,545  (_merge==3)\n",
    "\n",
    "\n",
    ". \n",
    ". * Now, you can perform a regression with the count as the dependent variable, and\tboth group-level\tand\tindivid\n",
    "> ual-level variables as predictors\n",
    ". //poisson donations summer related, irr maxiter(5)\n",
    ". mepoisson donations  summer:, irr maxiter(3)\n",
    "option maxiter() not allowed\n",
    "r(198);\n",
    "\n",
    "end of do-file\n",
    "\n",
    "r(198);\n",
    "\n",
    ". do \"/var/folders/sx/fd6zgj191mx45hspzbgwzlnr0000gn/T//SD16143.000000\"\n",
    "\n",
    ". poisson donations summer related, irr iter(5)\n",
    "\n",
    "Iteration 0:  Log likelihood = -3695885.2  \n",
    "Iteration 1:  Log likelihood = -3695885.2  \n",
    "\n",
    "Poisson regression                                   Number of obs =   184,671\n",
    "LR chi2(2)    = 678618.06\n",
    "Prob > chi2   =    0.0000\n",
    "Log likelihood = -3695885.2                          Pseudo R2     =    0.0841\n",
    "\n",
    "\n",
    "donations         IRR   Std. err.      z    P>z     [95% conf. interval]\n",
    "\n",
    "summer    1.140067   .0002599   574.93   0.000     1.139558    1.140577\n",
    "related    .8815915  .0001849  -600.86   0.000     .8812292     .881954\n",
    "_cons     506.0029   .0827662  3.8e+04   0.000     505.8407    506.1651\n",
    "\n",
    "Note: _cons estimates baseline incidence rate.\n",
    "\n",
    ". \n",
    "end of do-file\n",
    "\n",
    ". do \"/var/folders/sx/fd6zgj191mx45hspzbgwzlnr0000gn/T//SD16143.000000\"\n",
    "\n",
    ". mepoisson donations  summer:, irr iter(3)\n",
    "\n",
    "Fitting fixed-effects model:\n",
    "\n",
    "Iteration 0:  Log likelihood = -4216081.9  \n",
    "Iteration 1:  Log likelihood = -4146341.1  \n",
    "Iteration 2:  Log likelihood = -4146315.8  \n",
    "Iteration 3:  Log likelihood = -4146315.8  \n",
    "\n",
    "Refining starting values:\n",
    "\n",
    "Grid node 0:  Log likelihood =          .\n",
    "Grid node 1:  Log likelihood =          .\n",
    "Grid node 2:  Log likelihood =          .\n",
    "Grid node 3:  Log likelihood = -3985497.5\n",
    "\n",
    "Refining starting values (unscaled likelihoods):\n",
    "\n",
    "Grid node 0:  Log likelihood = -3985497.5\n",
    "\n",
    "Fitting full model:\n",
    "\n",
    "Iteration 0:  Log likelihood = -3985497.5  \n",
    "Iteration 1:  Log likelihood = -3985497.5  (not concave)\n",
    "Iteration 2:  Log likelihood = -3985497.5  (not concave)\n",
    "Iteration 3:  Log likelihood = -3985497.5  (not concave)\n",
    "convergence not achieved\n",
    "\n",
    "Mixed-effects Poisson regression                Number of obs     =    186,545\n",
    "Group variable: summer                          Number of groups  =          2\n",
    "\n",
    "Obs per group:\n",
    "min =     51,402\n",
    "avg =   93,272.5\n",
    "max =    135,143\n",
    "\n",
    "Integration method: mvaghermite                 Integration pts.  =          7\n",
    "\n",
    "Wald chi2(0)      =          .\n",
    "Log likelihood = -3985497.5                     Prob > chi2       =          .\n",
    "\n",
    "donations   Inc. rate   Std. err.      z        P>z       [95% conf. interval]\n",
    "\n",
    "_cons       491.1811   .3627498       8390.79   0.000     490.4706    491.8926\n",
    "\n",
    "summer       \n",
    "var(_cons)   10.00109          .                             .           .\n",
    "\n",
    "Note: Estimates are transformed only in the first equation to incidence rate.\n",
    "Warning: Convergence not achieved.\n",
    "\n",
    ". \n",
    "end of do-file\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 3\n",
    "\n",
    "If your single-level Poisson model has provided reasonable results, you can potentially use these to set the starting values for the corresponding parameters in the multi-level model. However, note that `mepoisson` doesn't have a straightforward `from()` option like some other optimization functions in Stata to input starting values.\n",
    "\n",
    "Here's an example with the hypothetical Stata code. In this case, the `if 1 {}` part is a condition to check; you can replace it with an actual condition or ignore it:\n",
    "\n",
    "```stata\n",
    "* Run the single-level Poisson model first to get starting estimates\n",
    "poisson donations summer related, irr iter(5)\n",
    "\n",
    "* Capture the estimates\n",
    "matrix start_vals = e(b)\n",
    "\n",
    "* Display the estimates; just for checking\n",
    "di \"Starting values from the single-level model:\"\n",
    "matrix list start_vals\n",
    "\n",
    "* Run the multi-level model, possibly using starting values (note that mepoisson does not allow you to specify starting values directly)\n",
    "mepoisson donations || summer:, irr iter(3)\n",
    "```\n",
    "\n",
    "In your pseudo-code, you mention merging the aggregated data back to the individual-level data. If you've actually aggregated the data, remember that this will affect the fit of your model. Also, it's worth mentioning that Stata does not permit setting the starting values in the `mepoisson` command, so the `from(start_vals)` part won't be applicable here.\n",
    "\n",
    "If convergence continues to be a problem, you may want to explore whether Stata's ML engine options (like different optimization algorithms or providing analytical derivatives if possible) could be useful, though these can be quite technical and are generally used when other options have failed. \n",
    "\n",
    "Remember to interpret the results carefully, especially when there are convergence issues, as they may not be reliable.\n",
    "\n",
    "---\n",
    "\n",
    "I'm open to suggestions including python and machine learning\n",
    "\n",
    "---\n",
    "\n",
    "If you are interested in Python-based solutions, you could use the `statsmodels` package, which provides classes for estimating and interpreting models for many different statistical models, including Poisson and Negative Binomial models. The `scikit-learn` package also provides a `PoissonRegressor` class for fitting Poisson regression models.\n",
    "\n",
    "For hierarchical/multilevel models, the `pymc3` package allows for Bayesian hierarchical models, and you can specify initial values.\n",
    "\n",
    "Here's a simplified example using `statsmodels`:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Let's assume `df` is your DataFrame containing 'donations', 'summer', 'related' \n",
    "# df = pd.read_csv('your_data.csv')\n",
    "\n",
    "# Adding constant term for intercept\n",
    "df['intercept'] = 1.0\n",
    "\n",
    "# Defining the dependent variable (y) and independent variables (X)\n",
    "y = df['donations']\n",
    "X = df[['intercept', 'summer', 'related']]\n",
    "\n",
    "# Fit Poisson regression model\n",
    "model = sm.GLM(y, X, family=sm.families.Poisson()).fit()\n",
    "\n",
    "# Show model summary\n",
    "print(model.summary())\n",
    "```\n",
    "\n",
    "For a hierarchical model with `pymc3`:\n",
    "\n",
    "```python\n",
    "import pymc3 as pm\n",
    "import numpy as np\n",
    "\n",
    "# Again, assume 'donations', 'summer', 'related' are your data\n",
    "# donations = np.array(df['donations'])\n",
    "# summer = np.array(df['summer'])\n",
    "# related = np.array(df['related'])\n",
    "\n",
    "with pm.Model() as model:\n",
    "    # Hyperpriors\n",
    "    mu_intercept = pm.Normal('mu_intercept', mu=0, sd=1)\n",
    "    sigma_intercept = pm.HalfNormal('sigma_intercept', sd=1)\n",
    "\n",
    "    mu_slope = pm.Normal('mu_slope', mu=0, sd=1)\n",
    "    sigma_slope = pm.HalfNormal('sigma_slope', sd=1)\n",
    "    \n",
    "    # Intercept and Slope\n",
    "    Intercept = pm.Normal('Intercept', mu=mu_intercept, sd=sigma_intercept, shape=len(set(summer)))\n",
    "    Slope = pm.Normal('Slope', mu=mu_slope, sd=sigma_slope, shape=len(set(summer)))\n",
    "\n",
    "    # Expected value\n",
    "    theta = pm.math.exp(Intercept[summer] + Slope[summer]*related)\n",
    "\n",
    "    # Likelihood\n",
    "    donations_obs = pm.Poisson('donations_obs', mu=theta, observed=donations)\n",
    "\n",
    "    # Fitting the model\n",
    "    trace = pm.sample(2000)\n",
    "```\n",
    "\n",
    "You can inspect the `trace` object to look at parameter estimates and other diagnostic information.\n",
    "\n",
    "Remember that this is a simplified example, and you'll need to adjust the models according to your actual data and research questions.\n",
    "\n",
    "---\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13. Automate\n",
    "\n",
    "**Why automate?**\n",
    "- Make life simpler.\n",
    "- Ensure reproducibility.\n",
    "- Enhance efficiency.\n",
    "- Foster collaboration.\n",
    "- Achieve scalability.\n",
    "\n",
    "**Efficiency Through Command Line**\n",
    "\n",
    "Bash, the Bourne Again SHell, is a cornerstone of computing mastery. Beyond command execution, Bash exemplifies streamlined operations and a profound understanding. It offers **controlled automation**. While GUIs provide a superficial interaction, Bash delves deeper, facilitating a richer conversation with the system.\n",
    "\n",
    "**Overshadowed by Aesthetic Simplicity**\n",
    "\n",
    "In the face of intuitive GUIs and their user-friendly designs, the depth of Bash is often overshadowed. For many, clickable icons and immediate visual feedback make command-lines appear daunting. Yet, those willing to embrace Bash find the experience rewarding.\n",
    "\n",
    "**Early steps**\n",
    "\n",
    "**Jupyter**\n",
    "\n",
    "Jupyter Notebooks optimize data analysis automation, integrating code, text, and visuals. They're paramount in this Fena platform, simplifying work-sharing and reproducibility.\n",
    "\n",
    "**Workflow**\n",
    "\n",
    "1. **Initiate a Jupyter Notebook**: Using Google Colab, Jupyter Lab, or VS Code.\n",
    "2. **Develop Code**: Use the built-in code editor in Jupyter Lab or VS Code. Our unique workflow even allows code writing in non-traditional Jupyter languages like Stata.\n",
    "3. **Execute the Code**.\n",
    "4. **Save the Notebook**.\n",
    "5. **Share the Notebook**: Ranging from basic sharing via Google Colab to advanced methods like pushing to GitHub pages.\n",
    "\n",
    "**Python**\n",
    "\n",
    "Python's large user community and integration with Jupyter make it an ideal choice for automating data analysis.\n",
    "\n",
    "<Details>\n",
    "\n",
    "**Libraries Overview**:\n",
    "\n",
    "- **Data Analysis**: Use `Pandas` for data manipulation and analysis.\n",
    "  \n",
    "- **Visualization**: `Matplotlib` and `Seaborn` are renowned for plotting and graphing.\n",
    "\n",
    "- **Machine Learning**: `Scikit-learn` simplifies machine learning model creation.\n",
    "\n",
    "- **Statistical Modeling**: Utilize `Statsmodels`.\n",
    "\n",
    "- **Bayesian Modeling**: Turn to `PyMC3`.\n",
    "\n",
    "- **Deep Learning**: Opt for `TensorFlow`, `Keras`, or `PyTorch`.\n",
    "\n",
    "- **Web Scraping**: `Scrapy`, `Beautiful Soup`, `Selenium`, and `Requests` are your go-to libraries.\n",
    "\n",
    "- **Natural Language Processing**: Use `NLTK`, `SpaCy`, or `Gensim`.\n",
    "\n",
    "- **Network Analysis**: Explore networks with `NetworkX`, `PyGraphviz`, or `PyTorch Geometric`.\n",
    "\n",
    "</Details>\n",
    "\n",
    "**Later steps**\n",
    "\n",
    "1. Familiarize yourself with basic Unix commands.\n",
    "2. Construct a bash script for executing code in Python, R, Stata, etc.\n",
    "3. Set a cron job to automate the bash script execution.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
